% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% LaTeX4EI Example for Cheat Sheets
%
% @encode: 	UTF-8, tabwidth = 4, newline = LF
% @author:	LaTeX4EI
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %


% ======================================================================
% Document Settings
% ======================================================================

% possible options: color/nocolor, english/german, threecolumn
% default: color, english
\documentclass[english]{latex4ei/latex4ei_sheet}
\usepackage{dsfont}
\usepackage{textcomp}
\usepackage{bbm}
\usepackage{breqn}
\usepackage{mathtools}
\usepackage{polynom}
% set document information
\title{Model\\Predictive\\Control}


% DOCUMENT_BEGIN ===============================================================
\begin{document}

\maketitle	% requires ./img/Logo.pdf

\section{Basics}
\begin{sectionbox}
\textbf{Compact set}: Subset of Euclidean space being closed (\textit{i.e., containing all its limit points}) and bounded (\textit{i.e., having all its points lie within some fixed distance of each other}).\\
\textbf{Matrix Inversion}: $A^{-1}=\frac{1}{\det{A}}\cdot\textrm{adj}(A)$
$$\begin{bmatrix}a & b \\ c & d\end{bmatrix}^{-1} = \frac{1}{ad-bc} \begin{bmatrix}d & -b \\ -c & a\end{bmatrix}$$
\textbf{Eigenvalues}: $\det(A-\lambda I)=0$\\
\textbf{Eigenvectors}: $(A-\lambda I)\cdot v=0$\\
\textbf{Rule of Sarrus}: $A_{3\times3}=\begin{bmatrix}a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{bmatrix}$
\begin{multline*}
    \det(A_{3\times3})=a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}\\-a_{31}a_{22}a_{13}-a_{32}a_{23}a_{11}-a_{33}a_{21}a_{12}
\end{multline*}
For system equations $y_i=f_i(x)$, you can find $x$ with \textbf{Least Squares}: \\ $$x=\arg \min_{x} \left[\sum\limits_{i=1}^{n}\left(y_i-f_i(x)\right)^2\right]$$
($\rightarrow$ \textit{Calculate derivative, set to zero and find corresponding value for} $x$)

\end{sectionbox}

\section{Introduction}
\begin{sectionbox}

\subsection{System Class}
Time-invariant discrete-time dynamical control system \\
$x(k+1)=f(x(k), u(k));\quad k=0,1,2,...\quad x(0)=x_0$\\
with state $x(k)\in\mathbb{R}^n$ and control input $u(k)\in\mathbb{R}^m$.\\

Notation:\\
${\underline{u}^{N}\coloneqq\{u(0), u(1), \ldots u(N-1)\}} \\ {\underline{x}_{u}^{N}\left(x_{0}\right)\coloneqq\left\{x_{0}, x_{\underline{u}}\left(1, x_{0}\right), \ldots x_{\underline{u}}\left(N, x_{0}\right)\right\}}$ \\ 
or if context is clear for brevity: \\ ${\underline{x}_{\underline{u}}^{N}\left(x_{0}\right)\coloneqq\left\{x_{0}, x(1), \ldots x(N)\right\}}$\\

\subsection{Cost Function}
Infinite Horizon:
\[J_{\infty}\left(x_{0}, \underline{u}^{\infty}\right)=\sum_{k=0}^{\infty} l\left(x_{\underline{u}}\left(k, x_{0}\right), u(k)\right)\]
Finite Horizon:
\[J_{N}\left(x_{0}, \underline{u}^{N}\right)=\sum_{k=0}^{N-1} l\left(x_{\underline{u}}\left(k, x_{0}\right), u(k)\right)+J_{f}\left(x_{\underline{u}}\left(N, x_{0}\right)\right)\]
with stage cost $l(x,u)$ and target cost $J_f(x)$.\\

\subsection{Constraints}
Input constraints: $u(k) \in \mathbb{U}$ \\ 
State constraints: $x(k) \in \mathbb{X}, k=1,2,3, \ldots ;\; x(N) \in \mathbb{X}_{f}$ \\ \\
Admissible Controls:  $\mathcal{U}_{N}\left(x_{0}\right)\coloneqq\left\{\underline{u} |\left(x_{0}, \underline{u}\right) \in \mathbb{Z}\right\}$ \\ Feasible Initial Values: $\mathcal{X}_{N}\coloneqq\left\{x_{0} \in \mathbb{X} | \mathcal{U}_{N}\left(x_{0}\right) \neq \emptyset\right\}$\\
with 
\begin{multline*}
\mathbb{Z}_{N}\coloneqq\Big\{\left(x_{0}, \underline{u}\right) | u(k) \in \mathbb{U}, x_{\underline{u}}\left(k, x_{0}\right) \in \mathbb{X}, \\ k=0,1, \ldots, N-1 ; x_{\underline{u}}\left(N, x_{0}\right) \in \mathbb{X}_{f}\Big\}
\end{multline*}

\end{sectionbox}
\begin{sectionbox}

\subsection{Optimization Problem}
$$
\mathbb{P}_{N}\left(x_{0}\right): J_{N}^{*}\left(x_{0}\right)=\min _{\underline{u}}\left\{J_{N}\left(x_{0}, \underline{u}\right) | \underline{u} \in \mathcal{U}_{N}\left(x_{0}\right)\right\}
$$
Assumption 1:\\
$f,\,l,\,J_f$ are continuous with $f(0,0)=0,\; l(0,0)=0,\; J_f(0)=0$.\vspace{0.1cm}
\\
Assumption 2:\\
$\mathbb{X}$ is closed, $\mathbb{X}_f$ and $\mathbb{U}$ are compact and all sets contain the origin.\vspace{0.1cm}
\\
Under \textit{Assumption 1} and \textit{Assumption 2}, the optimization problem $\mathbb{P}_N(x_0)$ has a solution for all $x_0\in\mathcal{X}_N$. \\($\rightarrow$ Theorem of Weierstrass: Sets are sequentially compact \textit{and} every bounded sequence of complex numbers contains at least one convergent subsequence.)\\

\subsection{Controller}
$\kappa_{N}\left(x_{0}\right)=u^{*}\left(0, x_{0}\right)$ \\ 
with optimal control input $u^{*}\left(0, x_{0}\right)$ from solution of $\mathbb{P}_{N}\left(x_{0}\right)$, \\$\underline{u}^{*}=\left\{u^{*}\left(0, x_{0}\right), u^{*}\left(1, x_{0}\right), \ldots u^{*}\left(N-1, x_{0}\right)\right\}$.\\

\subsection{Basic time-invariant MPC algorithm}
System: $x^{+}=f(x, u)$\\ 
Cost: $J(x, \underline{u})=\sum\limits_{k=0}^{N-1} l(x(k), u(k))+J_{f}(x(N))$ \\
Constraints: $x(k) \in \mathbb{X}, u(k) \in \mathbb{U} \text { for all } k \in \mathbb{N}_{0} \text { and } x(N) \in \mathbb{X}_{f}$ \\
where $N$ is the prediction horizon.
\begin{itemize}
    \item Measure $x$, determine $\mathcal{U}_N(x)$
    \item Solve $\mathbb{P}_N(x)$ and obtain $\underline{u}^*(x)$
    \item Control with $\kappa_N(x)$ such that $x^+=f(x,\kappa_N(x))$
    \item Repeat for $x\coloneqq x^+$
\end{itemize}\vspace{0.2cm}

\subsection{Constrained Optimization in a nutshell}
Cost function: $\min F(z)$\\
Equality constraints: $g(z)=0$\\
Inequality constraints: $h(z)\leq 0$\\
\\
\textbf{a)} unconstrained\\
If $z^*$ is minimum, then $\nabla F(z^*)=0$.\\
\textbf{b)} equality constrained\\
Lagrange function $L=F(z)+\lambda^{\top} g(z)$ with Lagrange multiplier $\lambda$. \\ 
If $z^{*}$ is minimum, then $\nabla_{z} L\left(z^{*}, \lambda^{*}\right)=0$ and $\nabla_{\lambda} L\left(z^{*}, \lambda^{*}\right)=0$. \\
\textbf{c)} inequality constrained\\
Lagrange function $L=F(z)+\mu^{\top} h(z)$ with KKT multiplier $\mu$. \\
If $z^{*}$ is minimum then $\nabla_{z} L\left(z^{*}, \mu^{*}\right)=0$ and $\mu^{*} \geq 0, h\left(z^{*}\right) \leq 0$ and $\mu_{i}^{*} h_{i}\left(z^{*}\right)=0$ for all $i$.\\
\\
Optimum for cost function at horizon $N$ for $J_N=0$. If only one constraint is active, use \textbf{b)} to look at constrained edge of control input and derive the remaining optimal control inputs.

\end{sectionbox}
\section{Dynamic Programming}
\begin{sectionbox}

\subsection{Problem Statement}
Time-invariant discrete-time dynamical control system \textit{(can be nonlinear)}:\\
$x(k+1)=f(x(k), u(k)) ; \quad k=0,1,2, \ldots \quad x(0)=x_{0}$ \\
Cost: $V\left(x_{0}, \underline{u}\right)=\sum\limits_{k=0}^{N-1} l(x(k), u(k))+V_{f}(x(N))$ \\
State constraints: $x(k) \in \mathbb{X},\; k=0,1, \ldots, N-1,\; x(N) \in \mathbb{X}_{f}$\\
Input constraints: $u(k) \in \mathbb{U}, k=1,2, \ldots, N-1$ \vspace{0.1cm}\\ 
Find $\underline{u}=\{u(0),u(1), \ldots, u(N-1)\}$ \\where $u(k)=\mu_{k}(x(k))$ are control laws.
\vspace{0.1cm}\\
\textbf{Advantages and Disadvantages}:\\
$+$ We get control laws \qquad $+$ Costly optimization is done offline\\
$-$ Curse of dimensionality
\vspace{0.1cm}\\
\textbf{Comparisson to MPC}:
\begin{itemize}
    \item Dynamic Programming (DP) has one large horizon.
    \item MPC delivers control action for only one specific realisation.
    \item DP is optimal for full problem and target constraints are satisfied.\\
    MPC target constraints are reached asymptotically\\ $\rightarrow$ \textit{might have stability problem}
\end{itemize}


\end{sectionbox}
\begin{sectionbox}

\subsection{Notation}
Cost-to-go: $V_{i}\left(x, \underline{u}^{i}\right)=\sum\limits_{k=i}^{N-1} l(x(k), u(k))+V_{f}(x(N))$ \\
with $\underline{u}^{i}=\{u(i), u(i+1), \ldots, u(N-1)\}$ \\
Optimal cost-to-go: $V_{i}^{*}(x)=\min _{\underline{u}^{i} \in \Upsilon_{i}(x)} V_{i}\left(x, \underline{u}^{i}\right)$\quad
with
\begin{multline*}
    \Upsilon_{i}(x)\coloneqq\\\left\{\underline{u}^{i} | \text{ for initial state } x(i)=x: u(k) \in \mathbb{U}, k=i ,\ldots, N-1;\\x(k) \in \mathbb{X}, k=i+1, \ldots ,N-1 ; x(N) \in \mathbb{X}_{f}\right\}
\end{multline*}
and $\Xi_{i}\coloneqq\left\{x \in \mathbb{X} | \Upsilon_{i}(x) \neq \emptyset\right\}$ \\
\\
Recursive construction of feasible sets $\Xi_{i}$ from behind:\\ 
$\Xi_{N}=\mathbb{X}_{f}$ \\ 
$\Xi_{i}=\left\{x(i) \in \mathbb{X} | x(i+1) \in \Xi_{i+1} \text { with } u(i) \in \mathbb{U}\right\},\\
i=N-1, N-2, \ldots 0$\\

\subsection{Bellman Recursion}
Recursive calculation of optimal-cost $V_i^*$, starting with the terminal cost: \\
$V_{N}^{*}(x(N))=V_f(x(N))$ \; $\rightarrow$ \; $V_{N-1}^{*}=\min\{V^{*}_N+\ldots\}$ \; $\rightarrow$ \;\ldots\\
In general, with $l(x(i),u(i))$ as cost of only the current $i$:
\begin{multline*}
V_{i}^{*}(x(i))=\min _{u(i)}\Big\{l(x(i), u(i))+V_{i+1}^{*}\left(f(x(i), u(i))\right) \;| \\u(i) \in \mathbb{U}, x(i) \in \mathbb{X}, f(x(i), u(i)) \in \Xi_{i+1}\Big\},\\
i=N-1,N-2,\ldots,0
\end{multline*}
Use system $f(x(i),u(i))$ to substitute $x(i+1)$ in $V^{*}_{i+1}(x(i+1))$ and solve $\frac{\partial V_{i}}{\partial u(i)}=0$ to get optimal control input $u^{*}(i)=ax(i)$.\\ Insert $u^{*}(i)$ into $V^{*}_{i}(x(i))$ to get optimal cost-to-go.

\end{sectionbox}

\section{Stability}
\begin{sectionbox}

\subsection{Stability Concepts}
System class: $x^{+}=\Tilde{f}(x)$ \quad $\rightarrow$ \ Equilibrium point: $x_{eq}=\Tilde{f}(x_{eq})$\\
Open loop: $x^{+}=f(x)$ \; $\longleftrightarrow$ \; Closed loop: $x^{+}=f(x,u)$\vspace{0.1cm}
\\
Assumption:\\
If $\Tilde{f}$ is not continuous, it is at least locally bounded.\vspace{0.1cm}
\\
Definition of stability in the sense of Lyapunov:\\
Equilibrium point $x_{\mathrm{eq}}=0$ of $x^{+}=\hat{f}(x)$ is locally stable, if $\forall\varepsilon>0$ there exists a $\delta>0$ s.t. for all $\|x(0)\| \leq \delta(\varepsilon)$, it holds that $\|x(k)\| \leq \varepsilon$ for all $k>0$.
\begin{itemize}
    \item Locally asymptotically stable, if in addition $\lim _{k \rightarrow \infty}\|x(k)\|=0$ for $x(0)$ close to the origin.
    \item Globally asymptotically stable, if in addition $\lim _{k \rightarrow \infty}\|x(k)\|=0$ for all $x(0) \in \mathbb{R}^{n}$.
    \item Asymptotically stable in $\mathcal{X}$, if in addition $\lim _{k \rightarrow \infty}\|x(k)\|=0$ for all $x(0) \in \mathcal{X}$, where $\mathcal{X}$ is positive.
\end{itemize}\vspace{0.2cm}

Definition of \textbf{positive invariance}:\\
$\mathcal{X}$ is positive invariant for $x^{+}=\Tilde{f}(x)$, if $\Tilde{f}(x)\in\mathcal{X}$ for all $x\in\mathcal{X}$.\\
(\textit{Once a system trajectory enters set} $\mathcal{X}$, \textit{it will never leave it again.})\\

\textbf{Comparison Functions}:\\
Necessary as candidate Lyapunov function is discontinuous.\\ 
$\rightarrow$ Optimal control $\underline{u}^{*}$ is solution of a optimum, convergence to different local minima possible.\\
$\rightarrow$ Special case: unconstrained MPC is continuous\\
\\
Definition:
\begin{itemize}
    \item A function $\alpha$ is a class $\mathcal{K}$ function, if it is continuous and strictly increasing with $\alpha(0)=0$.
    \item A function $\alpha$ is a class $\mathcal{K}_{\infty}$ function, if it a class $\mathcal{K}$ function and in addition unbounded.
    \item A function $\alpha$ is a class $\mathcal{PD}$ (\textit{positive definite}) function, if it is continuous with $\alpha(0)=0$ and $\alpha(x)>0$ for all $x\neq0$.
\end{itemize}

\end{sectionbox}
\begin{sectionbox}

Lyapunov's direct method:\\
A function $V\,:\,\mathbb{R}^{n}\:\rightarrow\:\mathbb{R}$ is a global Lyapunov function for the equilibrium of $x^{+}=\Tilde{f}(x)$, if $\alpha_1,\alpha_2\in\mathcal{K}_{\infty},\,\alpha_3\in\mathcal{PD}$ exist, such that for all $x\in\mathbb{R}^n$ condition \textbf{(1)} and \textbf{(2)} holds.\\
If $V$ is a global Lyapunov function for the equilibrium of $x^{+}=\Tilde{f}(x)$, then the equilibrium is globally asymptotically stable.\\
\\
Lyapunov's direct method (\textbf{constrained}):\\
A function $V\,:\,\mathcal{X}\:\rightarrow\:\mathbb{R}$ with $\mathcal{X}$ invariant is a Lyapunov function for the equilibrium of $x^{+}=\Tilde{f}(x)$ on $\mathcal{X}$, if $\alpha_1,\alpha_2\in\mathcal{K}_{\infty},\,\alpha_3\in\mathcal{PD}$ exist, such that for all $x\in\mathcal{X}$ condition \textbf{(1)} and \textbf{(2)} holds.\\
If $V$ is a Lyapunov function for the equilibrium of $x^{+}=\Tilde{f}(x)$ on $\mathcal{X}$, then the equilibrium is asymptotically stable on $\mathcal{X}$.\\

\begin{emphbox}
    (1) Bounded: $\alpha_{1}(\|x\|) \leq V(x) \leq \alpha_{2}(\|x\|)$ \\ 
    (2) Descent: $V(f(x))-V(x) \leq-\alpha_{3}(\|x\|)$\\
\end{emphbox}

\subsection{Assumptions for Stability}
Assumption 3:\\
$l(x, u)>\alpha_{l}(\|x\|) \quad \forall x \in \mathcal{X}_{N}, \forall u \in \mathbb{U}$ \\ 
$J_{f}(x) \leq \alpha_{f}(\|x\|) \quad \forall x \in \mathbb{X}_{f}$ where $\alpha_{l}, \alpha_{f}$ are class $\mathcal{K}_{\infty}$ functions.\\
\\
Assumption 4:\\
$J_f$ is a Control Lyapunov Function (CLF), that means $J_f(0)=0,\ J_f>0$ and there exists $u\in\mathbb{U}$ such that $J_f(f(x,u))-J_f(x)\leq-l(x,u)\ \forall x\in\mathbb{X}_f$.\\
If system is CLF, it is feedback stabilizable.\\
\\
Assumption 5:\\
$\mathbb{X}_f$ is control invariant, that means, if $x\in\mathbb{X}_f$ then there exists $u\in\mathbb{U}$ such that $f(x,u)\in\mathbb{X}_f$.\\ 

\subsection{Stability of MPC}
Under Assumptions 1 to 5, the equilibrium $x_{eq}$ is asymptotically stable in $\mathcal{X}_N$ for $x^{+}=f(x,\kappa_{N}(x))$.\\
\textit{Proof}: Choose Lyapunov function $V_N(x)=J_N(x,\underline{u}^{*})$ and show property (1) and (2) of Lyapunov direct method.\\

\subsection{Recursive Feasibility}
Definition: MPC is said to be recursively feasible, if one can assure that there is a solution to $\mathbb{P}_N(x^{+})$ having a solution of $\mathbb{P}_N(x)$.\\
\\
If $\mathbb{X}_f$ is control invariant, then
\begin{itemize}
    \item $\mathcal{X}_{j-1}\subseteq\mathcal{X}_{j},\;j=1,\ldots,N$
    \item $\mathcal{X}_{j-1}$ is control invariant, $j=1,\ldots,N$
    \item MPC is recursively feasible
\end{itemize}
To deal with infeasibility, soften hard constraints.\\
\\
To find feasible initial values $\mathcal{X}_1$ for an additional target constraint $\mathcal{X}_0=\mathbb{X}_f=\{0\}$, solve $x^{+}=f(x,u)=0$ and check which states satisfy target constraint.\\
\\
To determine $\mathcal{X}_1$ given an control invariant target set $\mathcal{X}_0=\mathbb{X}_f$, put in system dynamics $x^{+}$ for $x$ in $\mathbb{X}_f$ and check if state constraints are satisfied. $\mathcal{X}_1$ is then the set with adjusted system matrix and limits.
$$\mathcal{X}_1=\left\{\mathbf{A}\begin{bmatrix}x_1 \\ x_2 \end{bmatrix}\leq\begin{bmatrix}a \\ b \end{bmatrix}\right\}$$
With control constraints $a_u\leq u\leq b_u$, give feasible values subject to the constraints. E.g. for state $x=\left[x_1\ x_2\ x_3\right]^{\top}$\\ $\mathcal{X}_1=\{x| a_u \leq x_1 \leq b_u,\ x_1=x_3=-x_2\}$

\end{sectionbox}

\newpage
\section{MPC for Linear Systems}
\begin{sectionbox}

\subsection{System Class for Linear MPC}
System class: $x^{+}=A x+B u$ \\
Cost: $J_{N}(x, \underline{u})=\frac{1}{2} \sum\limits_{k=0}^{N-1}\|x(k)\|_{Q}^{2}+\|u(k)\|_{R}^{2}+\frac{1}{2}\|x(N)\|_{P_{f}}^{2}$ \\
Constraints: $x(k) \in \mathbb{X}, u(k) \in \mathbb{U}, x(N) \in \mathbb{X}_{f}$, where $\mathbb{X}$, $\mathbb{U}$ and $\mathbb{X}_{f}$ are convex polytopes\\

\subsection{LQ Control (non-receding finite horizon)}
For linear systems with quadratic cost and no constraints.\\
System Class: $x^{+}=A x+B u$ \\
Cost: $$V_{0}\left(x_{0}, u\right)=\frac{1}{2} \sum_{k=1}^{N-1}\underbrace{\|x(k)\|_{Q}^{2}}_{\substack{\text{penalize} \\ \text{bad performance}}}+\underbrace{\|u(k)\|_{R}^{2}}_{\substack{\text{penalize} \\ \text{actuator effort}}}+\frac{1}{2}\|x(N)\|_{P_{f}}^{2}$$ \\
Control law: $u(k)=K(k) x(k)$ \quad ($K$ \textit{is time-variant})\vspace{0.1cm}
\\
while for $k=0, \ldots, N-1$, with $P(N)=P_{f}$
$$K(k)=-\left(B^{\top} P(k+1) B+R\right)^{-1} B^{\top} P(k+1) A$$ and
\begin{multline*}
    \quad\ P(k)=A^{\top} P(k+1) A+Q-A^{\top} P(k+1) B\\\left(B^{\top} P(k+1) B+R\right)^{-1} B^{\top} P(k+1) A
\end{multline*}
Recursion for the Riccatti Matrix:
$$P(k)=A^{\top} P(k+1) A+Q+\boldsymbol{K}(k)^{\top}B^{\top} P(k+1)A$$
In addition Lyapunov function:\\ 
$V_{0}^{*}\left(x_{0}\right)=\frac{1}{2} x_{0}^{\top} P(0) x_{0}$\\

\subsection{LQ Control (infinite horizon)}
System Class: $x^{+}=A x+B u$ \\
Cost: $V(x, \underline{u})=\frac{1}{2} \sum\limits_{k=0}^{\infty}\|x(k)\|_{Q}^{2}+\|u(k)\|_{R}^{2}$ \\
\\
Control Law: $u(k)=K_{\infty} x(k)$, while \\ $K_{\infty}=-\left(B^{\top} P_{\infty} B+R\right)^{-1} B^{\top} P_{\infty} A$ and Riccati Equation:\\ 
${P_{\infty}=Q+K_{\infty}^{\top} R K_{\infty}+\left(A+B K_{\infty}\right)^{\top} P_{\infty}\left(A+B K_{\infty}\right)}$\\
\\
Stationary Riccatti Matrix:
$$P_{\infty}=A^{\top} P_{\infty} A+Q+\boldsymbol{K}_{\infty}^{\top}B^{\top} P_{\infty}A,\qquad P_{\infty}\geq 0$$

\subsection{MPC (constrained, receding horizon)}
Stability of equilibrium $x_{eq}=0$ under MPC, if\\
unconstrained: $P_{f}=P_{\infty}$\\
constrained:\\
1.) $P_{f}=P_{\infty}$ \\
2.) constraint admissibility: $\mathbb{X}_{f} \subseteq\{x \in \mathbb{X} | K x \in \mathbb{U}\}$ \\
3.) positive invariance: $x \in \mathbb{X}_{f} \Rightarrow x^{+}=\left(A+B K_{\infty}\right) x \in \mathbb{X}_{f}$\\

\subsection{Underlying Optimization Problem (QP)}
Using previews $x(k)=A^{k}x_{0}+A^{k-1}Bu(0)+\ldots+Bu(k-1)$\\
for all $k$ in horizon in cost function 
$$J_{N}\left(x_{0}, \underline{u}\right)=\frac{1}{2} \sum\limits_{k=0}^{N-1}\|x(k)\|_{Q}^{2}+\|u(k)\|_{R}^{2}+\frac{1}{2}\|x(N)\|_{P_{f}}^{2}$$
allows to transform the cost into $$J_N(x,\underline{u})=\frac{1}{2}\underline{u}^{\top}H(x_0)\underline{u}+c(x_{0})^{\top}\underline{u}+d(x_{0})$$
with $\underline{u}\in\mathcal{U}_{N}(x_{0})$
polytopes QP problem (= quadratic cost with linear constraints) allows for efficient numerics.

\end{sectionbox}


\section{Generalized Predictive Control (GPC)}
\begin{sectionbox}

\subsection{System Class}
Transfer function: $\frac{y(t)}{\Delta u(t-1)}=\frac{B(z^{-1})}{A(z^{-1})}$\\
System class:
$$A\left(z^{-1}\right) y(t)=B\left(z^{-1}\right) z^{-d} u(t-1)+C\left(z^{-1}\right) \frac{e(t)}{\Delta}$$
\begin{itemize}
    \item Denominator: $A\left(z^{-1}\right)=1+a_{1} z^{-1}+a_{2} z^{-2}+\ldots+a_{n} z^{-n}$
    \item Denumerator: $B\left(z^{-1}\right)=1+b_{1} z^{-1}+\ldots+b_{m} z^{-m}$, $m<n$
    \item $C\left(z^{-1}\right)$ for colored noise, in the following $C\left(z^{-1}\right)=1$
    \item $e(t)$: white noise with zero mean
    \\
    \item Shift operator: $z^{-k} y(t)=y(t-k)$
    \item Dead time: $z^{-d}$, in the following $d=0$
    \item $\Delta=1-z^{-1}$ (for $u(t) \leftrightarrow$ for $u(t-1)$: $\Delta=1$)
\end{itemize} \vspace{0.1cm}
Cost: 
$$J=\sum_{j=1}^{N} \delta(j)(\underbrace{\hat{y}(t+j | t)}_{\substack{\text{predicted} \\ \text{output}}}-\underbrace{w(t+j)}_{\substack{\text{future ref.} \\ \text{trajectory}}})^{2}+\sum_{j=1}^{M} \lambda(j)(\Delta u(t+j-1))
$$
\begin{itemize}
    \item Horizons: $N$ is prediction horizon, $M$ is control horizon, in the following $M=N$
    \item Weighting $\delta(j),\ \lambda(j)$
    \item Control input $\Delta u = u(t)-u(t-1)$
    \item Prediction from time $t$ to $t+j$:
\end{itemize}
$$\hat{y}(t+j | t)=G_{j}(z^{-1})\Delta u(t+j-1)+F_{j}(z^{-1})y(t)
$$

\subsection{Diophantine Equation}
Used to get rid of \textit{inbetween predictions}.\\
$\rightarrow$ Fewer equations than unknown variables\\
$1=E_{j} z^{-1} \tilde{A}\left(z^{-1}\right)+z^{-j} F_{j}\left(z^{-1}\right)$ with $\tilde{A}=\Delta A$ \\ $E_{j}\left(z^{-1}\right)$: polynomial of degree $j-1$ \\ $F_{j}\left(z^{-1}\right)$: polynomial of degree of $\tilde{A}$
\\ \\

Prediction:\\ $\underline{y}=\underline{G u}+\underline{p}$ \quad(prediction $\underline{p}$ often denoted as $f$)\\
where the choice of $\underline{y}$ and $\underline{u}$ as:
$$
\begin{array}{l}{\underline{y}=[\hat{y}(t+1 | t), \hat{y}(t+2 | t), \ldots, \hat{y}(t+N | t)]^{\top}} \\ 
\underline{u}=[\Delta u(t), \Delta u(t+1), \ldots, \Delta u(t+N-1)]^{\top}
\end{array}
$$
defines $G$ and $\underline{p}$:
$$G=\left[\begin{array}{cccc}{g_{0}} & {0} & {\dots} & {0} \\ {g_{1}} & {g_{0}} & {\dots} & {0} \\ {\vdots} & {\vdots} & {\vdots} & {\vdots} \\ {g_{N-1}} & {g_{N-2}} & {\dots} & {g_{0}}\end{array}\right]$$
$$\underline{p}=\underbrace{\underline{F}\left(z^{-1}\right) y(t)}_{\text{past values of } y}+\underbrace{\underline{G}^{\prime}\left(z^{-1}\right) \Delta u(t-1)}_{\text{future \& past control inputs}}$$
with\\
$G_{j}\left(z^{-1}\right)=B\left(z^{-1}\right) E_{j}\left(z^{-1}\right)$\\
$\underline{G}^{\prime}\left(z^{-1}\right)=\left[\begin{array}{c}{\left(G_{1}\left(z^{-1}\right)-g_{0}\right) z} \\ {\left(G_{2}\left(z^{-1}\right)-g_{0}-g_{1} z^{-1}\right) z^{2}}\end{array}\right]$\\
$\underline{F}\left(z^{-1}\right)=\left[F_{1}\left(z^{-1}\right), F_{2}\left(z^{-1}\right), \ldots, F_{N}\left(z^{-1}\right)\right]^{\top}$\\
and $g_{j}$ $j$-th coefficients of polynomial $G_{j}$.

\end{sectionbox}
\begin{sectionbox}
\textbf{Excursion:}
Polynomials $E_{j}\left(z^{-1}\right)$ and $F_{j}\left(z^{-1}\right)$ can be obtained by dividing $1$ by $\tilde{A}(z^{-1})=\Delta A(z^{-1})$ until the remainder can be factorized as $z^{-j}F_{j}(z^{-1})$, e.g.:\\
\( \begin{aligned} (1 \qquad \ \qquad):(\overbrace{1-2z^{-1}+2z^{-2}-z^{-3}}^{\Delta A(z^{-1})})=\overbrace{\overbrace{1}^{E_1}+2z^{-1}}^{E_2}+\ \ldots \end{aligned}\\
\begin{aligned}
\frac{1-2 z^{-1}+2 z^{-2}-z^{-3}}{\qquad 2 z^{-1}-2 z^{-2}+z^{-3}} &  \frac{}{\ \ \qquad \qquad \Rightarrow z^{-1} F_{1}\left(z^{-1}\right)}
\end{aligned}\\
\begin{aligned}
\frac{\qquad 2 z^{-1}-4 z^{-2}+4 z^{-3}-2 z^{-4}}{\qquad \qquad \qquad 2z^{-2}- 3z^{-3}+2 z^{-4}} & \frac{}{\Rightarrow z^{-2} F_{2}\left(z^{-1}\right)} & \ldots \end{aligned} \)
\\
For $N=2$:\\
$E_1(z^{-1})=1$, \quad $E_2(z^{-1})=1+2z^{-1}$\\
\\
$\rightarrow\frac{z^{-1}F_1(z^{-1})}{z^{-1}}=F_1(z^{-1})=2 -2z^{-1}+z^{-2}$\\
\\
$\rightarrow\frac{z^{-2}F_2(z^{-1})}{z^{-2}}=F_2(z^{-1})=2 -3z^{-1}+2z^{-2}$\\

\subsection{QP Problem}
Cost (\textit{with reference} $w$): $$J=u\left(G^{T} Q G+R\right) \underline{u}+2(\underline{p}-\underline{w})^{T} Q G \underline{u}+(\underline{p}-\underline{w})^{T} Q(\underline{p}-\underline{w})$$ is minimized by control sequence of future controls \\
$\underline{u}=-\left(G^{T} Q G+R\right)^{-1} G^{T} Q(\underline{p}-w)$\\
where only $\underline{u}_{1}=\Delta u(t)$ is applied as control.
\vspace{0.1cm}\\
E.g. for horizon $N=3$:\\ $u(t)=u(t-3)+\Delta u(t-2)+\Delta u(t-1)+\Delta u(t)$\\
where $\Delta u(t)$ is the first element of $\underline{u}$.

\end{sectionbox}


\section{Numerics}
\begin{sectionbox}

\subsection{Nonlinear Programming (NP)}
Cost function: $F(z)$\\
Equality constraints: $g(z)=0$\\
Inequality constraints: $h(z)\leq 0$\\
Active Set: $\mathcal{A}=\left\{j | \mu_{j}>0\right\}$ (\textit{set of active constraints})
\vspace{0.1cm}\\
\textbf{Sequential}: Recursive Elimination (\textit{find optimal} $\underline{u}$)\\
$+$ Small NP problem\\
$-$ Sensitive dependance for larger N
\vspace{0.1cm}\\
\textbf{Parallel}: Full Discretization (\textit{find optimal} $\underline{u}$ \textit{and} $\underline{x}$)\\
$+$ Simple to implement \qquad $+$ Easier for state constraints\\
$-$ Larger NP problem \; \qquad $-$ Many constraints
\vspace{0.1cm}\\
\textbf{Compromise}: Multiple Shooting
\vspace{0.1cm}\\
Necessary conditions for a minimum:\\
If $z^{*}$ is feasible minimum, then $\nabla_{z} L\left(z^{*}, \lambda^{*}, \mu^{*}\right)=0$ and $\nabla_{\lambda} L\left(z^{*}, \lambda^{*}, \mu^{*}\right)=0\quad$ with $\quad\mu^{*} \geq 0$, $h\left(z^{*}\right) \leq 0\quad$ and $\mu_{i}^{*} h_{i}\left(z^{*}\right)=0\quad$ for all $i$ with Lagrange function\\ $L=F(z)+\lambda^{\top} g(z)+\mu^{\top} h(z)$ with multipliers $\lambda$ and $\mu$.\\

\subsection{Unconstrained Minimization: Newton's Method}
Find minimum $z^{*}$ numerically as follows
\begin{itemize}
    \item Initialize: Guess $z^{(0)}$ close to $z^{*}$ for $k=0,1,2,\ldots$
    \item Update (calculate tangent and corresponding root value):\\
    $z^{(k+1)}=z^{(k)}+\alpha^{(k)} d^{(k)}$ where\\ $d^{(k)}=-\left(\nabla^{2} F\left(z^{(k)}\right)\right)^{-1} \nabla F\left(z^{(k)}\right)$ (search direction)\\
    and step length $\alpha^{(k)}=\textrm{argmin}\ F(z^{(k)}+\alpha d^{(k)})$ (line search)
    \item Stop if $\|\nabla F(z^{(k)})\|<\epsilon_{tol}$ (\textit{after 1 iteration if} $F$ \textit{is quadratic})
\end{itemize}\vspace{0.2cm}


\end{sectionbox}
\begin{sectionbox}

\subsection{Constrained Minimization: Quadratic Programming}
Applies for QP problem class:\\
Quadratic cost function: $F(z)=\frac{1}{2}z^{\top}Hz+c^{\top}z$\\
Linear equality constraints: $g(z)=Ez+e=0$\\
Liner inequality constraints: $h(z)=Iz+i\leq 0$\\
\\
Find minimum $z^{*}$ numerically as follows
\begin{itemize}
    \item Initialize: Guess initial active set $\mathcal{A}_0$ for $k=0,1,2,\ldots$\\
    If all active constraints are known, solvable in one iteration.
    \item Update optimization variables $z$ with $\frac{\partial L}{\partial z}$.\\
    Inequality constraints from active set $\mathcal{A}_k$ are treated as equality constraints. Non-active constraints are neglected.
    \item Update active set:\\
    When for $j \in \mathcal{A}_{k}: \mu_{j}^{(k+1)}<0$, delete const. $j$ from active set\\
    When for $j \notin \mathcal{A}_{k} I_{j} z^{(k+1)}+i_{j} \geq 0$, add constraint $j$ to active set and thus get $\mathcal{A}_{k+1}$
    \item Stop if $\mathcal{A}_{k}$ is not active anymore.
\end{itemize}\vspace{0.2cm}

\subsection{Constrained Minimization: Sequential QP}
Combine Newton's Methods (linearization of NP problem to obtain QP problem) and QP method (choice of feasible active set of linearized problem).\\

\subsection{Constrained Minimization: Interior Point}
Cost function: $F(z)$\\
Equality constraints: $g(z)=0$\\
Former inequality constraints, now equality constraints: $h(z)+s=0$\\
New inequality constraints: $s\geq 0$\\
\\
Lagrange Function $L=F(z)+y^{\top}g(z)+w^{\top}(h(z)+s)-\mu^{\top}s$\\
Necessary Conditions that are related to inequality constraints:\\
$s \geq 0 $, $\mu \geq 0$ and $s^{\top}\mu=0$\\
\\
Relax complementary conditions $s^{\top}\mu=0$ by introducing barrier parameter $\epsilon$ to $s^{\top}\mu=\epsilon$ and solve with $\epsilon \rightarrow 0$.\\

\subsection{Soft Constraints}
Softened minimization problem with penalty term $l(\epsilon)$:
$$\min_{x}f(x)+l(\epsilon), \text{ s.t. }g(x)\leq\epsilon,\;\epsilon \geq 0$$
where $\epsilon$ defines the degree of softness.
\vspace{0.1cm}\\
\textbf{Quadratic penalty}: $l\epsilon)=v\cdot\epsilon^{2}$ with $v>0$\\
Feasible solution $x^*$ for the original problem is not the same for the softened problem for any $v>0$ and $\epsilon=0$.
\vspace{0.1cm}\\
\textbf{Linear penalty}: $l(\epsilon)=u\cdot\epsilon$\\
Same solution as original problem for $u>\mu^*\geq 0$, where $\mu^*$ is the optimal Lagrange multiplier for the original problem.
\end{sectionbox}


\section{Robust MPC}
\begin{sectionbox}

\subsection{Robust Stability}
Does state reach vicinity of the origin under bounded small disturbances?
\vspace{0.1cm}
\textbf{Types of uncertainties:} Parametric uncertainty, modeling errors, etc.\\
E.g. additive disturbance: $x^{+}=f(x,u)+w$ where $w$ is disturbance and $w\in\mathbb{W}$, where $\mathbb{W}$ is bounded.
\vspace{0.1cm}\\
Standard controllers (e.g. PID) have inherent robustness.\\ Nominal Robust Stability only if Lyapunov Function is continuous \\(e.g. for linear MPC).\\

\subsection{Tube base MPC for Linear Systems}
Nominal model: $z^{+}=Az+Bu$\\
Disturbed (real) model: $x^{+}=Ax+Bu+w$
\vspace{0.1cm}\\
Use tube $S(k)$, $k=0,1,2,\ldots$ to check \textbf{constraint admissibility}:\\
Set $S(k)$ is such that all possible trajectories $x(k)$  (apply all possible disturbances) of real disturbed system fulfill $x(k)\in\{z(k) \oplus S(k)\}$, i.e. do not violate constraints.\\
\textbf{MPC feedback control}: $u^{*}=v^{*}+K(x-z)$, where $K$ is found offline. Appropiate choice of $K$ reduces the size of the tube.\\
Optimize cost to find $v^{*}$ such that $x^{*}$ is constraint admissible by constraint tightening using the tube.

\end{sectionbox}


% DOCUMENT_END =================================================================
\end{document}
